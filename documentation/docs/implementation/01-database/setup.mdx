
# Database Setup Guide

This guide walks you through setting up the database infrastructure for NeuraLabs, including PostgreSQL for persistent storage and Redis for caching and session management.

## Overview

NeuraLabs uses a dual-database architecture:
- **PostgreSQL**: Primary data storage for users, workflows, and metadata
- **Redis**: Session management, caching, and real-time features

## Prerequisites

<Callout type="info">
  Ensure Docker is installed and running on your system before proceeding.
</Callout>

## Quick Setup with Docker

### 1. Navigate to Database Directory

```bash
cd neuralabs-sui/database
```

### 2. Create Environment File

<CodeBlock language="bash" title="database/.env">
{`# PostgreSQL Configuration
POSTGRES_USER=neuralabs
POSTGRES_PASSWORD=your_secure_password_here
POSTGRES_DB=neuralabs_db
POSTGRES_PORT=5432

# Redis Configuration
REDIS_PORT=6379
REDIS_PASSWORD=your_redis_password_here

# PgAdmin Configuration (optional)
PGADMIN_DEFAULT_EMAIL=admin@neuralabs.org
PGADMIN_DEFAULT_PASSWORD=admin_password
PGADMIN_PORT=5050`}
</CodeBlock>

### 3. Start Database Services

<Tabs>
  <TabItem value="docker-compose" label="Docker Compose" default>
    ```bash
    # Start all database services
    docker-compose up -d

    # Verify services are running
    docker-compose ps
    ```
  </TabItem>
  <TabItem value="individual" label="Individual Containers">
    ```bash
    # PostgreSQL
    docker run -d \
      --name neuralabs-postgres \
      -e POSTGRES_USER=neuralabs \
      -e POSTGRES_PASSWORD=your_password \
      -e POSTGRES_DB=neuralabs_db \
      -p 5432:5432 \
      -v postgres_data:/var/lib/postgresql/data \
      postgres:15-alpine

    # Redis
    docker run -d \
      --name neuralabs-redis \
      -p 6379:6379 \
      -v redis_data:/data \
      redis:7-alpine redis-server --requirepass your_redis_password
    ```
  </TabItem>
</Tabs>

## Database Schema

### Core Tables

<Tabs>
  <TabItem value="users" label="Users" default>
    ```sql
    CREATE TABLE users (
        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
        wallet_address VARCHAR(66) UNIQUE NOT NULL,
        username VARCHAR(50) UNIQUE,
        email VARCHAR(255),
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        last_login TIMESTAMP,
        is_active BOOLEAN DEFAULT true
    );

    CREATE INDEX idx_users_wallet ON users(wallet_address);
    CREATE INDEX idx_users_username ON users(username);
    ```
  </TabItem>
  <TabItem value="workflows" label="Workflows">
    ```sql
    CREATE TABLE workflows (
        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
        owner_id UUID REFERENCES users(id),
        name VARCHAR(255) NOT NULL,
        description TEXT,
        flow_data JSONB NOT NULL,
        version INTEGER DEFAULT 1,
        is_public BOOLEAN DEFAULT false,
        nft_address VARCHAR(66),
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    );

    CREATE INDEX idx_workflows_owner ON workflows(owner_id);
    CREATE INDEX idx_workflows_nft ON workflows(nft_address);
    ```
  </TabItem>
  <TabItem value="executions" label="Executions">
    ```sql
    CREATE TABLE workflow_executions (
        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
        workflow_id UUID REFERENCES workflows(id),
        user_id UUID REFERENCES users(id),
        status VARCHAR(50) NOT NULL,
        input_data JSONB,
        output_data JSONB,
        error_message TEXT,
        started_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        completed_at TIMESTAMP,
        execution_time_ms INTEGER
    );

    CREATE INDEX idx_executions_workflow ON workflow_executions(workflow_id);
    CREATE INDEX idx_executions_user ON workflow_executions(user_id);
    CREATE INDEX idx_executions_status ON workflow_executions(status);
    ```
  </TabItem>
</Tabs>

### Initialize Schema

Run the initialization script:

```bash
# Using Docker
docker exec -i neuralabs-postgres psql -U neuralabs -d neuralabs_db < ./database_schema.sql

# Or using Python script
cd database/notebooks
python initiate.py
```

## Redis Configuration

### Data Structures

<CodeBlock language="python" title="Redis Key Patterns">
{`# Session Management
session:{user_id}:{session_id} = {user_data, expires_at}

# Workflow Execution Cache
execution:{execution_id} = {status, progress, intermediate_results}

# Rate Limiting
rate_limit:{user_id}:{endpoint} = request_count

# Real-time Updates
channel:workflow:{workflow_id} = execution_updates
channel:chat:{session_id} = chat_messages`}
</CodeBlock>

### Connection Configuration

<Tabs>
  <TabItem value="python" label="Python" default>
    ```python
    import redis
    from redis.sentinel import Sentinel

    # Standard connection
    redis_client = redis.Redis(
        host='localhost',
        port=6379,
        password='your_redis_password',
        decode_responses=True
    )

    # Connection pool for performance
    pool = redis.ConnectionPool(
        host='localhost',
        port=6379,
        password='your_redis_password',
        max_connections=50
    )
    redis_client = redis.Redis(connection_pool=pool)
    ```
  </TabItem>
  <TabItem value="nodejs" label="Node.js">
    ```javascript
    const redis = require('redis');

    const client = redis.createClient({
        url: 'redis://:your_redis_password@localhost:6379',
        socket: {
            reconnectStrategy: (retries) => Math.min(retries * 50, 1000)
        }
    });

    client.on('error', (err) => console.error('Redis Client Error', err));
    await client.connect();
    ```
  </TabItem>
</Tabs>

## Performance Optimization

### PostgreSQL Tuning

<CodeBlock language="sql" title="Performance Settings">
{`-- Adjust based on available RAM
ALTER SYSTEM SET shared_buffers = '256MB';
ALTER SYSTEM SET effective_cache_size = '1GB';
ALTER SYSTEM SET maintenance_work_mem = '64MB';
ALTER SYSTEM SET work_mem = '4MB';

-- Connection pooling
ALTER SYSTEM SET max_connections = 200;

-- Write performance
ALTER SYSTEM SET checkpoint_completion_target = 0.9;
ALTER SYSTEM SET wal_buffers = '16MB';
ALTER SYSTEM SET default_statistics_target = 100;

-- Apply changes
SELECT pg_reload_conf();`}
</CodeBlock>

### Redis Optimization

<CodeBlock language="conf" title="redis.conf">
{`# Memory management
maxmemory 2gb
maxmemory-policy allkeys-lru

# Persistence
save 900 1
save 300 10
save 60 10000

# Performance
tcp-backlog 511
timeout 0
tcp-keepalive 300

# Slow log
slowlog-log-slower-than 10000
slowlog-max-len 128`}
</CodeBlock>

## Monitoring & Maintenance

### Health Checks

<Tabs>
  <TabItem value="postgres" label="PostgreSQL" default>
    ```sql
    -- Check database size
    SELECT pg_database_size('neuralabs_db');

    -- Active connections
    SELECT count(*) FROM pg_stat_activity;

    -- Long running queries
    SELECT pid, now() - pg_stat_activity.query_start AS duration, query 
    FROM pg_stat_activity 
    WHERE (now() - pg_stat_activity.query_start) > interval '5 minutes';

    -- Table sizes
    SELECT schemaname, tablename, pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
    FROM pg_tables
    ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
    ```
  </TabItem>
  <TabItem value="redis" label="Redis">
    ```bash
    # Memory usage
    redis-cli info memory

    # Connected clients
    redis-cli info clients

    # Operations per second
    redis-cli info stats

    # Slow queries
    redis-cli slowlog get 10
    ```
  </TabItem>
</Tabs>

### Backup Strategy

<CodeBlock language="bash" title="Automated Backup Script">
{`#!/bin/bash
# backup.sh

# PostgreSQL backup
docker exec neuralabs-postgres pg_dump -U neuralabs neuralabs_db | gzip > backup_$(date +%Y%m%d_%H%M%S).sql.gz

# Redis backup
docker exec neuralabs-redis redis-cli --rdb /data/dump.rdb BGSAVE

# Upload to cloud storage (optional)
# aws s3 cp backup_*.sql.gz s3://neuralabs-backups/postgres/
# aws s3 cp dump.rdb s3://neuralabs-backups/redis/`}
</CodeBlock>

## Troubleshooting

<details>
  <summary>Connection refused error</summary>
  
  1. Check if containers are running:
  ```bash
  docker ps
  ```
  
  2. Verify port bindings:
  ```bash
  docker port neuralabs-postgres
  docker port neuralabs-redis
  ```
  
  3. Test connectivity:
  ```bash
  pg_isready -h localhost -p 5432
  redis-cli ping
  ```
</details>

<details>
  <summary>Performance issues</summary>
  
  1. Check slow queries in PostgreSQL:
  ```sql
  SELECT * FROM pg_stat_statements ORDER BY total_time DESC LIMIT 10;
  ```
  
  2. Analyze Redis memory:
  ```bash
  redis-cli --bigkeys
  ```
  
  3. Review connection pools and increase if needed
</details>

<details>
  <summary>Data corruption</summary>
  
  1. Stop services immediately
  2. Create backup of current state
  3. Run PostgreSQL recovery:
  ```bash
  docker exec neuralabs-postgres pg_dump -U neuralabs -f /backup.sql neuralabs_db
  ```
  4. Contact support if issues persist
</details>

## Next Steps

With your database infrastructure ready:

1. [Configure PostgreSQL](./postgresql-config) for optimal performance
2. [Set up Redis](./redis-config) for caching and sessions
3. [Design your schema](./schema-design) for the application
4. [Implement migrations](./migrations) for version control

<Callout type="success">
  Your database infrastructure is now ready! Continue to the [Backend Setup](../03-backend/setup) to connect your application.
</Callout>
---
id: hpc-aws-bedrock-troubleshooting
title: Troubleshooting
sidebar_label: Troubleshooting
sidebar_position: 4
---

import { Card, CardHeader, CardTitle, CardDescription } from '@site/src/components/Card';
import { Callout } from '@site/src/components/Callout';
import { Features, Feature } from '@site/src/components/Features';
import { CollapsibleCodeBlock, InlineCodeCard } from '@site/src/components/CodeBlock';
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from '@theme/CodeBlock';

# AWS Bedrock Troubleshooting

This guide helps you diagnose and resolve common issues when integrating AWS Bedrock with the HPC Neura Execution Engine.

## Common Issues

<Features>
  <Feature title="Authentication Errors" icon="/img/icons/security.svg">
    Credential and permission issues
  </Feature>
  <Feature title="Model Access Issues" icon="/img/icons/ai-workflow.svg">
    Model availability and access problems
  </Feature>
  <Feature title="Performance Problems" icon="/img/icons/hpc.svg">
    Latency and timeout issues
  </Feature>
</Features>

## Authentication and Permissions

### Invalid Credentials

<Tabs>
  <TabItem value="error" label="Error Message" default>
    <div style={{ marginTop: '1rem' }}>
      <Callout type="error" title="Unable to locate credentials">
        <pre>
{`ClientError: Unable to locate credentials
NoCredentialsError: Unable to locate credentials`}
        </pre>
      </Callout>
    </div>
  </TabItem>
  
  <TabItem value="diagnosis" label="Diagnosis">
    <div style={{ marginTop: '1rem' }}>
      <h4>Check your credentials:</h4>
      <CollapsibleCodeBlock
        title="Verify Credentials"
        language="bash"
      >
{`# Check if environment variables are set
echo $AWS_ACCESS_KEY_ID
echo $AWS_SECRET_ACCESS_KEY
echo $AWS_REGION

# Test AWS CLI access
aws sts get-caller-identity

# Verify .env file format
cat .env | grep AWS_`}
      </CollapsibleCodeBlock>
    </div>
  </TabItem>
  
  <TabItem value="solution" label="Solution">
    <div style={{ marginTop: '1rem' }}>
      <h4>Fix credential issues:</h4>
      <ol>
        <li>Ensure credentials are properly set in `.env` file</li>
        <li>Remove any quotes around credential values</li>
        <li>Check for extra spaces or line breaks</li>
        <li>Restart your application after updating credentials</li>
      </ol>
      
      <CollapsibleCodeBlock
        title="Correct .env Format"
        language="bash"
      >
{`# Correct format (no quotes, no spaces)
AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE
AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
AWS_REGION=us-east-2`}
      </CollapsibleCodeBlock>
    </div>
  </TabItem>
</Tabs>

### Access Denied Errors

<Card>
  <CardHeader>
    <CardTitle>AccessDeniedException</CardTitle>
  </CardHeader>
  <div style={{ padding: '1rem' }}>
    <Callout type="error">
      <pre>
{`AccessDeniedException: User is not authorized to perform: bedrock:InvokeModel`}
      </pre>
    </Callout>
    
    <h4>Common Causes:</h4>
    <ul>
      <li>Missing IAM permissions</li>
      <li>Model access not granted</li>
      <li>Incorrect region</li>
      <li>Policy not attached to user</li>
    </ul>
    
    <CollapsibleCodeBlock
      title="Debug IAM Permissions"
      description="Check and fix permission issues"
      language="bash"
    >
{`# Check attached policies
aws iam list-attached-user-policies --user-name your-bedrock-user

# Verify policy permissions
aws iam get-policy-version \
  --policy-arn arn:aws:iam::account:policy/BedrockAccess \
  --version-id v1

# Test specific model access
aws bedrock invoke-model \
  --model-id anthropic.claude-3-haiku-20240307-v1:0 \
  --body '{"messages":[{"role":"user","content":"test"}],"max_tokens":1}' \
  --region us-east-2`}
    </CollapsibleCodeBlock>
  </div>
</Card>

## Model Access Issues

### Model Not Found

<Tabs>
  <TabItem value="standard" label="Foundation Models" default>
    <div style={{ marginTop: '1rem' }}>
      <Callout type="error" title="ValidationException">
        <pre>
{`ValidationException: The provided model identifier is invalid.
Model ID: anthropic.claude-3-haiku-20240307-v1:0`}
        </pre>
      </Callout>
      
      <h4>Solutions:</h4>
      <ol>
        <li><strong>Verify model availability in your region:</strong></li>
      </ol>
      
      <CollapsibleCodeBlock
        title="Check Model Availability"
        language="python"
      >
{`import boto3

def check_model_availability(region='us-east-2'):
    """List all available models in a region."""
    bedrock = boto3.client('bedrock', region_name=region)
    
    try:
        response = bedrock.list_foundation_models()
        models = response['modelSummaries']
        
        print(f"\\nAvailable models in {region}:")
        for model in models:
            print(f"- {model['modelId']}: {model['modelName']}")
            
        # Check specific model
        model_id = "anthropic.claude-3-haiku-20240307-v1:0"
        if any(m['modelId'] == model_id for m in models):
            print(f"\\n✓ {model_id} is available")
        else:
            print(f"\\n✗ {model_id} is NOT available in {region}")
            
    except Exception as e:
        print(f"Error: {e}")

# Run check
check_model_availability('us-east-2')`}
      </CollapsibleCodeBlock>
    </div>
  </TabItem>
  
  <TabItem value="inference" label="Inference Profiles">
    <div style={{ marginTop: '1rem' }}>
      <Callout type="error" title="Inference Profile Error">
        <pre>
{`ValidationException: Invocation of model ID deepseek.r1-v1:0 with 
on-demand throughput isn't supported. Retry your request with the 
ID or ARN of an inference profile that contains this model.`}
        </pre>
      </Callout>
      
      <h4>Solution:</h4>
      <p>Use the full ARN for models requiring inference profiles:</p>
      
      <CollapsibleCodeBlock
        title="Using Inference Profile ARN"
        language="python"
      >
{`# Incorrect - using model ID directly
model_id = "deepseek.r1-v1:0"  # ❌ Won't work

# Correct - using full inference profile ARN
model_id = "arn:aws:bedrock:us-east-2:559050205657:inference-profile/us.deepseek.r1-v1:0"  # ✓

# In your flow definition
nodes:
  reasoning_node:
    type: llm_text
    model: arn:aws:bedrock:us-east-2:559050205657:inference-profile/us.deepseek.r1-v1:0
    max_tokens: 8000`}
      </CollapsibleCodeBlock>
    </div>
  </TabItem>
</Tabs>

### Model Access Not Granted

<Card>
  <CardHeader>
    <CardTitle>Model Access Request Required</CardTitle>
  </CardHeader>
  <div style={{ padding: '1rem' }}>
    <Callout type="warning">
      Even with proper IAM permissions, you must request access to each model through the AWS Console.
    </Callout>
    
    <h4>How to Request Model Access:</h4>
    <ol>
      <li>Go to <strong>AWS Bedrock Console</strong></li>
      <li>Navigate to <strong>Model access</strong></li>
      <li>Click <strong>Manage model access</strong></li>
      <li>Select desired models and submit request</li>
      <li>Wait for approval (usually instant)</li>
    </ol>
    
    <CollapsibleCodeBlock
      title="Verify Model Access"
      description="Script to check which models you have access to"
      language="python"
    >
{`import boto3
import json

def test_model_access(region='us-east-2'):
    """Test which models are accessible."""
    bedrock = boto3.client('bedrock', region_name=region)
    bedrock_runtime = boto3.client('bedrock-runtime', region_name=region)
    
    # Get list of models
    models = bedrock.list_foundation_models()['modelSummaries']
    
    print("Testing model access...")
    accessible = []
    denied = []
    
    for model in models[:10]:  # Test first 10
        model_id = model['modelId']
        try:
            # Minimal test invocation
            body = json.dumps({
                "messages": [{"role": "user", "content": "test"}],
                "max_tokens": 1
            })
            
            bedrock_runtime.invoke_model(
                modelId=model_id,
                body=body,
                contentType='application/json'
            )
            
            accessible.append(model_id)
            print(f"✓ {model_id}: ACCESS GRANTED")
            
        except Exception as e:
            if "no access" in str(e).lower():
                denied.append(model_id)
                print(f"✗ {model_id}: NO ACCESS")
            else:
                print(f"? {model_id}: {type(e).__name__}")
    
    return accessible, denied`}
    </CollapsibleCodeBlock>
  </div>
</Card>

## Connection and Timeout Issues

### Timeout Errors

<Tabs>
  <TabItem value="read-timeout" label="Read Timeout" default>
    <div style={{ marginTop: '1rem' }}>
      <Callout type="error" title="ReadTimeoutError">
        <pre>
{`ReadTimeoutError: Read timeout on endpoint URL`}
        </pre>
      </Callout>
      
      <h4>Solutions:</h4>
      
      <CollapsibleCodeBlock
        title="Increase Timeout Settings"
        language="python"
      >
{`from botocore.config import Config

# Configure longer timeouts
config = Config(
    read_timeout=900,  # 15 minutes for large responses
    connect_timeout=60,
    retries={
        'max_attempts': 3,
        'mode': 'adaptive'
    }
)

# Apply to client
bedrock_runtime = boto3.client(
    'bedrock-runtime',
    config=config,
    region_name='us-east-2'
)

# In .env file
BEDROCK_READ_TIMEOUT=900
BEDROCK_CONNECTION_TIMEOUT=60`}
      </CollapsibleCodeBlock>
    </div>
  </TabItem>
  
  <TabItem value="connection-timeout" label="Connection Timeout">
    <div style={{ marginTop: '1rem' }}>
      <Callout type="error" title="ConnectionTimeoutError">
        <pre>
{`ConnectionTimeoutError: Connect timeout on endpoint URL`}
        </pre>
      </Callout>
      
      <h4>Common Causes:</h4>
      <ul>
        <li>Network connectivity issues</li>
        <li>Firewall blocking AWS endpoints</li>
        <li>VPC endpoint misconfiguration</li>
      </ul>
      
      <CollapsibleCodeBlock
        title="Test Connectivity"
        language="bash"
      >
{`# Test DNS resolution
nslookup bedrock-runtime.us-east-2.amazonaws.com

# Test connectivity
curl -I https://bedrock-runtime.us-east-2.amazonaws.com

# Check VPC endpoints (if using)
aws ec2 describe-vpc-endpoints \
  --filters Name=service-name,Values=com.amazonaws.region.bedrock-runtime

# Test with AWS CLI
aws bedrock-runtime invoke-model \
  --model-id anthropic.claude-3-haiku-20240307-v1:0 \
  --body '{"messages":[{"role":"user","content":"test"}],"max_tokens":1}' \
  --region us-east-2`}
      </CollapsibleCodeBlock>
    </div>
  </TabItem>
</Tabs>

### Rate Limiting

<Card>
  <CardHeader>
    <CardTitle>ThrottlingException</CardTitle>
  </CardHeader>
  <div style={{ padding: '1rem' }}>
    <Callout type="error">
      <pre>
{`ThrottlingException: Rate exceeded`}
      </pre>
    </Callout>
    
    <h4>Solutions:</h4>
    
    <CollapsibleCodeBlock
      title="Implement Retry Logic"
      description="Handle rate limits with exponential backoff"
      language="python"
    >
{`import time
import random
from botocore.exceptions import ClientError

def invoke_with_retry(bedrock_runtime, model_id, body, max_retries=5):
    """Invoke model with automatic retry on throttling."""
    
    for attempt in range(max_retries):
        try:
            response = bedrock_runtime.invoke_model(
                modelId=model_id,
                body=body,
                contentType='application/json'
            )
            return response
            
        except ClientError as e:
            if e.response['Error']['Code'] == 'ThrottlingException':
                if attempt < max_retries - 1:
                    # Exponential backoff with jitter
                    wait_time = (2 ** attempt) + random.uniform(0, 1)
                    print(f"Rate limited. Waiting {wait_time:.1f}s...")
                    time.sleep(wait_time)
                else:
                    raise
            else:
                raise
    
# Configure automatic retries in boto3
from botocore.config import Config

config = Config(
    retries={
        'max_attempts': 5,
        'mode': 'adaptive',  # Automatic exponential backoff
        'adaptive_retry_wait_time': 5.0
    }
)`}
    </CollapsibleCodeBlock>
  </div>
</Card>

## Streaming Issues

### DeepSeek Streaming Errors

<Card>
  <CardHeader>
    <CardTitle>DeepSeek Reasoning Stream Issues</CardTitle>
  </CardHeader>
  <div style={{ padding: '1rem' }}>
    <p>DeepSeek models have special streaming behavior with reasoning traces:</p>
    
    <CollapsibleCodeBlock
      title="Handle DeepSeek Streaming"
      description="Properly parse DeepSeek's reasoning output"
      language="python"
    >
{`def process_deepseek_stream(stream_response):
    """Process DeepSeek streaming response with reasoning."""
    
    reasoning_buffer = []
    answer_buffer = []
    in_reasoning = False
    in_answer = False
    
    for event in stream_response['body']:
        chunk = json.loads(event['chunk']['bytes'].decode())
        
        if 'delta' in chunk and 'text' in chunk['delta']:
            text = chunk['delta']['text']
            
            # Detect reasoning section
            if '<think>' in text:
                in_reasoning = True
                text = text.replace('<think>', '')
            elif '</think>' in text:
                in_reasoning = False
                text = text.replace('</think>', '')
                # Process complete reasoning
                reasoning = ''.join(reasoning_buffer)
                print(f"[Reasoning]: {reasoning}")
                reasoning_buffer = []
                
            # Detect answer section
            elif '<answer>' in text:
                in_answer = True
                text = text.replace('<answer>', '')
            elif '</answer>' in text:
                in_answer = False
                text = text.replace('</answer>', '')
                
            # Append to appropriate buffer
            if in_reasoning:
                reasoning_buffer.append(text)
            elif in_answer:
                answer_buffer.append(text)
                yield text  # Stream answer to user
                
    return ''.join(answer_buffer)`}
    </CollapsibleCodeBlock>
  </div>
</Card>

## Performance Optimization

### Slow Response Times

<Features>
  <Feature title="Model Selection" icon="/img/icons/ai-workflow.svg">
    Use appropriate model size
  </Feature>
  <Feature title="Batching" icon="/img/icons/database.svg">
    Process multiple requests together
  </Feature>
  <Feature title="Caching" icon="/img/icons/hpc.svg">
    Cache common responses
  </Feature>
</Features>

<CollapsibleCodeBlock
  title="Performance Diagnostics"
  description="Measure and improve response times"
  language="python"
>
{`import time
import statistics

def benchmark_models(bedrock_runtime, prompt, models):
    """Benchmark response times for different models."""
    
    results = {}
    
    for model_id in models:
        times = []
        
        for i in range(5):  # Run 5 tests
            start = time.time()
            
            try:
                response = bedrock_runtime.invoke_model(
                    modelId=model_id,
                    body=json.dumps({
                        "messages": [{"role": "user", "content": prompt}],
                        "max_tokens": 100,
                        "temperature": 0.5
                    }),
                    contentType='application/json'
                )
                
                # Read response
                result = json.loads(response['body'].read())
                
                elapsed = time.time() - start
                times.append(elapsed)
                
            except Exception as e:
                print(f"Error with {model_id}: {e}")
                break
        
        if times:
            results[model_id] = {
                'mean': statistics.mean(times),
                'min': min(times),
                'max': max(times),
                'median': statistics.median(times)
            }
    
    # Print results
    print("\\nPerformance Results:")
    print("-" * 60)
    for model, stats in results.items():
        print(f"{model}:")
        print(f"  Average: {stats['mean']:.2f}s")
        print(f"  Range: {stats['min']:.2f}s - {stats['max']:.2f}s")
        print()
    
    return results`}
</CollapsibleCodeBlock>

## Debugging Tools

### Enable Debug Logging

<CollapsibleCodeBlock
  title="Debug Configuration"
  description="Enable detailed logging for troubleshooting"
  language="bash"
>
{`# Environment variables for debugging
export AWS_DEBUG=true
export BEDROCK_DEBUG=true
export BEDROCK_LOG_LEVEL=DEBUG
export BOTO_LOG_LEVEL=DEBUG

# Python logging configuration
import logging
import boto3

# Enable boto3 debug logging
boto3.set_stream_logger('boto3', logging.DEBUG)
boto3.set_stream_logger('botocore', logging.DEBUG)
boto3.set_stream_logger('urllib3', logging.DEBUG)

# Custom logger for your application
logger = logging.getLogger('bedrock_debug')
logger.setLevel(logging.DEBUG)
handler = logging.StreamHandler()
formatter = logging.Formatter(
    '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
handler.setFormatter(formatter)
logger.addHandler(handler)`}
</CollapsibleCodeBlock>

### Request/Response Inspection

<CollapsibleCodeBlock
  title="Inspect API Calls"
  description="Log and analyze Bedrock API interactions"
  language="python"
>
{`import json
from datetime import datetime

class BedrockDebugger:
    """Debug helper for Bedrock API calls."""
    
    def __init__(self, bedrock_runtime):
        self.client = bedrock_runtime
        self.log_file = f"bedrock_debug_{datetime.now():%Y%m%d_%H%M%S}.json"
        self.calls = []
    
    def invoke_model(self, **kwargs):
        """Wrapper for invoke_model with logging."""
        
        # Log request
        request_log = {
            'timestamp': datetime.now().isoformat(),
            'method': 'invoke_model',
            'model_id': kwargs.get('modelId'),
            'request_body': json.loads(kwargs.get('body', '{}')),
            'content_type': kwargs.get('contentType')
        }
        
        try:
            # Make actual call
            start_time = time.time()
            response = self.client.invoke_model(**kwargs)
            elapsed = time.time() - start_time
            
            # Log response
            response_body = json.loads(response['body'].read())
            response['body'] = response_body  # For return
            
            request_log['response'] = {
                'status': 'success',
                'elapsed_seconds': elapsed,
                'response_metadata': response['ResponseMetadata'],
                'body': response_body
            }
            
        except Exception as e:
            request_log['response'] = {
                'status': 'error',
                'error_type': type(e).__name__,
                'error_message': str(e)
            }
            raise
        
        finally:
            # Save log
            self.calls.append(request_log)
            with open(self.log_file, 'w') as f:
                json.dump(self.calls, f, indent=2)
        
        return response
    
    def print_summary(self):
        """Print summary of API calls."""
        print(f"\\nAPI Call Summary ({len(self.calls)} calls):")
        print("-" * 60)
        
        for i, call in enumerate(self.calls):
            print(f"\\nCall #{i+1}:")
            print(f"  Model: {call['model_id']}")
            print(f"  Status: {call['response']['status']}")
            if 'elapsed_seconds' in call['response']:
                print(f"  Time: {call['response']['elapsed_seconds']:.2f}s")
            if call['response']['status'] == 'error':
                print(f"  Error: {call['response']['error_message']}")

# Usage
debugger = BedrockDebugger(bedrock_runtime)
response = debugger.invoke_model(
    modelId='anthropic.claude-3-haiku-20240307-v1:0',
    body=json.dumps({...}),
    contentType='application/json'
)
debugger.print_summary()`}
</CollapsibleCodeBlock>

## Common Error Reference

<Card>
  <CardHeader>
    <CardTitle>Quick Error Reference</CardTitle>
  </CardHeader>
  <div style={{ padding: '1rem' }}>
    <table>
      <thead>
        <tr>
          <th>Error</th>
          <th>Likely Cause</th>
          <th>Quick Fix</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><code>NoCredentialsError</code></td>
          <td>Missing AWS credentials</td>
          <td>Set AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY</td>
        </tr>
        <tr>
          <td><code>AccessDeniedException</code></td>
          <td>IAM permissions missing</td>
          <td>Add bedrock:InvokeModel permission</td>
        </tr>
        <tr>
          <td><code>ValidationException</code></td>
          <td>Invalid model ID or parameters</td>
          <td>Check model availability in region</td>
        </tr>
        <tr>
          <td><code>ThrottlingException</code></td>
          <td>Rate limit exceeded</td>
          <td>Implement retry with backoff</td>
        </tr>
        <tr>
          <td><code>ModelTimeoutException</code></td>
          <td>Response took too long</td>
          <td>Increase timeout or use smaller model</td>
        </tr>
        <tr>
          <td><code>ResourceNotFoundException</code></td>
          <td>Model not found in region</td>
          <td>Switch region or use different model</td>
        </tr>
      </tbody>
    </table>
  </div>
</Card>

## Best Practices

<Callout type="success" title="Troubleshooting Checklist">
✅ Always check credentials and permissions first
✅ Verify model availability in your region
✅ Ensure model access is granted in console
✅ Use appropriate timeouts for your use case
✅ Implement proper error handling and retries
✅ Enable debug logging when investigating issues
✅ Monitor costs and usage to avoid surprises
</Callout>

## Getting Help

If you're still experiencing issues:

1. **Check AWS Status** - Visit [AWS Service Health Dashboard](https://status.aws.amazon.com/)
2. **Review CloudTrail Logs** - Check for API call failures
3. **Contact AWS Support** - For account or service-specific issues
4. **Community Resources** - AWS forums and Stack Overflow

<div style={{ display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(250px, 1fr))', gap: '1rem', marginTop: '1.5rem' }}>
  <Card>
    <CardHeader>
      <CardTitle>Setup Guide</CardTitle>
      <CardDescription>
        Review initial setup steps
      </CardDescription>
    </CardHeader>
    <div style={{ padding: '1rem', paddingTop: 0 }}>
      <a href="./setup" style={{ textDecoration: 'none' }}>
        Setup guide →
      </a>
    </div>
  </Card>
  
  <Card>
    <CardHeader>
      <CardTitle>Configuration</CardTitle>
      <CardDescription>
        Check configuration options
      </CardDescription>
    </CardHeader>
    <div style={{ padding: '1rem', paddingTop: 0 }}>
      <a href="./configuration" style={{ textDecoration: 'none' }}>
        Configuration →
      </a>
    </div>
  </Card>
</div>
---
id: hpc-flow-execution
title: Flow Execution
sidebar_label: Flow Execution
sidebar_position: 3
---

import { Card, CardHeader, CardTitle, CardDescription } from '@site/src/components/Card';
import { Callout } from '@site/src/components/Callout';
import { Features, Feature } from '@site/src/components/Features';
import { CollapsibleCodeBlock, InlineCodeCard } from '@site/src/components/CodeBlock';
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from '@theme/CodeBlock';

# Flow Execution

The Flow Execution system is the heart of the HPC Neura Execution Engine. It orchestrates how nodes execute, manages dependencies, handles data flow, and provides real-time visibility into the execution process.

## Execution Lifecycle

The execution of a flow follows a well-defined lifecycle from initiation to completion:

<Card>
  <CardHeader>
    <CardTitle>Execution Phases</CardTitle>
  </CardHeader>
  <div style={{ padding: '1rem' }}>
    <ol>
      <li><strong>Initialization</strong>: Flow is loaded, validated, and prepared for execution</li>
      <li><strong>Dependency Resolution</strong>: Node dependencies are analyzed and execution order determined</li>
      <li><strong>Node Execution</strong>: Nodes execute based on dependencies and data availability</li>
      <li><strong>Data Flow</strong>: Outputs from nodes flow to connected nodes as inputs</li>
      <li><strong>Completion</strong>: Flow reaches an end node or all paths are exhausted</li>
    </ol>
  </div>
</Card>

## Execution Model

### Dependency-Based Execution

The engine uses a sophisticated dependency-based execution model with two key mechanisms:

<Features>
  <Feature title="Downward Execution" icon="/img/icons/arrow-right.svg">
    Normal forward flow following control connections
  </Feature>
  <Feature title="Backtracking" icon="/img/icons/network.svg">
    Automatic resolution of missing data dependencies
  </Feature>
  <Feature title="Parallel Processing" icon="/img/icons/hpc.svg">
    Independent nodes execute simultaneously
  </Feature>
</Features>

<CollapsibleCodeBlock
  title="Execution Order Example"
  description="How the engine determines execution order"
  language="yaml"
>
{`# Given this flow structure:
nodes:
  A: { type: start }
  B: { type: chat_input, depends_on: [A] }
  C: { type: llm_text, depends_on: [B] }
  D: { type: selector, depends_on: [B] }
  E: { type: merger, depends_on: [C, D] }
  F: { type: end, depends_on: [E] }

# Execution order:
# 1. A (start) - no dependencies
# 2. B - depends on A
# 3. C and D in parallel - both depend only on B
# 4. E - waits for both C and D
# 5. F - depends on E

# Visual representation:
#     A
#     |
#     B
#    / \\
#   C   D
#    \\ /
#     E
#     |
#     F`}
</CollapsibleCodeBlock>

### Backtracking Mechanism

<Card>
  <CardHeader>
    <CardTitle>Understanding Backtracking</CardTitle>
  </CardHeader>
  <div style={{ padding: '1rem' }}>
    <p>Backtracking occurs when a node needs data from an upstream node that hasn't executed yet. This is common in complex flows with cross-path dependencies.</p>
    
    <h4>Key Characteristics:</h4>
    <ul>
      <li><strong>Automatic</strong>: Triggered when dependencies aren't satisfied</li>
      <li><strong>Minimal</strong>: Only executes required nodes</li>
      <li><strong>No Forward Propagation</strong>: Backtracked nodes don't trigger downstream execution</li>
      <li><strong>Data-Only</strong>: Purely for satisfying data dependencies</li>
    </ul>
    
    <CollapsibleCodeBlock
      title="Backtracking Example"
      description="How backtracking resolves dependencies"
      language="yaml"
    >
{`# Scenario: Node D needs data from Node B, but B hasn't executed
# Current execution at Node D:

1. Node D checks dependencies
2. Finds B.executed = false
3. Triggers backtracking to B
4. B executes with backtracking=true
5. B provides data to D
6. D continues execution
7. B's downstream nodes (C) are NOT triggered`}
    </CollapsibleCodeBlock>
  </div>
</Card>

### Downward Execution Control

<Card>
  <CardHeader>
    <CardTitle>Forward Flow Management</CardTitle>
  </CardHeader>
  <div style={{ padding: '1rem' }}>
    <p>Each node has a <code>downwards_execute</code> flag that controls whether it triggers downstream nodes after completion.</p>
    
    <table>
      <thead>
        <tr>
          <th>Flag Value</th>
          <th>Behavior</th>
          <th>Use Case</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><code>true</code> (default)</td>
          <td>Triggers all downstream connections</td>
          <td>Normal flow progression</td>
        </tr>
        <tr>
          <td><code>false</code></td>
          <td>Blocks downstream execution</td>
          <td>Conditional paths, error states</td>
        </tr>
      </tbody>
    </table>
    
    <CollapsibleCodeBlock
      title="Downward Execution with Typed Connections"
      description="How connection types affect execution flow"
      language="python"
    >
{`# In the execution engine:
if not backtracking and element.downwards_execute:
    for conn in element.connections:
        # With typed connections:
        if conn.connection_type in ["control", "both"]:
            await execute_element(conn.to_element)
        # Data-only connections are NOT followed for execution`}
    </CollapsibleCodeBlock>
  </div>
</Card>

### Execution Control

<Tabs>
  <TabItem value="flags" label="Execution Flags" default>
    <div style={{ marginTop: '1rem' }}>
      <h4>downwards_execute</h4>
      <p>Each node has a <code>downwards_execute</code> flag that controls whether its downstream connections should be executed.</p>
      
      <Card>
        <CardHeader>
          <CardTitle>Flag Behavior</CardTitle>
        </CardHeader>
        <div style={{ padding: '1rem' }}>
          <ul>
            <li><strong>True (default)</strong>: All downstream nodes will execute</li>
            <li><strong>False</strong>: Downstream execution is blocked</li>
            <li><strong>Modified by Case nodes</strong>: Can selectively enable/disable paths</li>
          </ul>
        </div>
      </Card>
    </div>
  </TabItem>
  
  <TabItem value="conditional" label="Conditional Execution">
    <div style={{ marginTop: '1rem' }}>
      <h4>Case-Based Control</h4>
      <p>Case nodes evaluate conditions and control which paths execute:</p>
      
      <CollapsibleCodeBlock
        title="Conditional Path Example"
        description="How case nodes control execution paths"
        language="yaml"
      >
{`case_node:
  type: case
  cases:
    - premium_path:
        variable1: user_type
        variable2: "premium"
        compare: "=="
    - standard_path:
        variable1: user_type
        variable2: "standard"
        compare: "=="

# If user_type == "premium":
#   - Connections to premium nodes are enabled
#   - Connections to standard nodes are disabled
# And vice versa`}
      </CollapsibleCodeBlock>
    </div>
  </TabItem>
  
  <TabItem value="error" label="Error Handling">
    <div style={{ marginTop: '1rem' }}>
      <h4>Execution Failures</h4>
      <p>When a node fails, the execution engine:</p>
      
      <ol>
        <li>Stops execution of downstream nodes</li>
        <li>Emits an <code>element_error</code> event</li>
        <li>Includes error details in the event stream</li>
        <li>Marks the flow as failed</li>
      </ol>
      
      <Callout type="warning">
        Node failures are not automatically retried. The flow developer must implement retry logic using conditional nodes if needed.
      </Callout>
    </div>
  </TabItem>
</Tabs>

## Data Flow During Execution

Data flows through connections as nodes execute:

<CollapsibleCodeBlock
  title="Data Flow Example"
  description="How data moves through a flow during execution"
  language="python"
>
{`# Step 1: Chat input node executes
chat_input_output = {
    "chat_input_001:chat_input": "What is blockchain?"
}

# Step 2: LLM node receives input via connection
llm_input = {
    "llm_001:prompt": chat_input_output["chat_input_001:chat_input"]
}

# Step 3: LLM node executes and produces output
llm_output = {
    "llm_001:response": "Blockchain is a distributed ledger...",
    "llm_001:confidence": 0.95
}

# Step 4: Multiple nodes can receive the output
selector_input = {
    "selector_001:data": llm_output["llm_001:response"]
}

analyzer_input = {
    "analyzer_001:text": llm_output["llm_001:response"],
    "analyzer_001:confidence": llm_output["llm_001:confidence"]
}`}
</CollapsibleCodeBlock>

## Real-Time Event Streaming

The execution engine provides real-time visibility through event streaming:

<Card>
  <CardHeader>
    <CardTitle>Event Types</CardTitle>
  </CardHeader>
  <div style={{ padding: '1rem' }}>
    <table>
      <thead>
        <tr>
          <th>Event</th>
          <th>When Emitted</th>
          <th>Data Included</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><code>flow_started</code></td>
          <td>Flow execution begins</td>
          <td>Flow ID, start time, initial inputs</td>
        </tr>
        <tr>
          <td><code>element_started</code></td>
          <td>Node begins execution</td>
          <td>Node ID, type, inputs</td>
        </tr>
        <tr>
          <td><code>element_completed</code></td>
          <td>Node finishes successfully</td>
          <td>Node ID, outputs, duration</td>
        </tr>
        <tr>
          <td><code>llm_chunk</code></td>
          <td>LLM streams response chunk</td>
          <td>Node ID, chunk content</td>
        </tr>
        <tr>
          <td><code>element_error</code></td>
          <td>Node encounters error</td>
          <td>Node ID, error message, stack trace</td>
        </tr>
        <tr>
          <td><code>flow_completed</code></td>
          <td>Flow execution completes</td>
          <td>Flow ID, final outputs, total duration</td>
        </tr>
      </tbody>
    </table>
  </div>
</Card>

<CollapsibleCodeBlock
  title="Event Stream Example"
  description="Sample event stream during flow execution"
  language="json"
>
{`// Flow started
{
  "event": "flow_started",
  "timestamp": "2025-01-27T10:00:00Z",
  "data": {
    "flow_id": "flow_abc123",
    "initial_inputs": {
      "chat_input_001": {
        "chat_input_001:chat_input": "Hello"
      }
    }
  }
}

// Node execution
{
  "event": "element_started",
  "timestamp": "2025-01-27T10:00:01Z",
  "data": {
    "element_id": "llm_001",
    "element_type": "llm_text",
    "inputs": {
      "llm_001:prompt": "Hello"
    }
  }
}

// Streaming response
{
  "event": "llm_chunk",
  "timestamp": "2025-01-27T10:00:02Z",
  "data": {
    "element_id": "llm_001",
    "chunk": "Hello! How can I"
  }
}

// Node completion
{
  "event": "element_completed",
  "timestamp": "2025-01-27T10:00:03Z",
  "data": {
    "element_id": "llm_001",
    "outputs": {
      "llm_001:response": "Hello! How can I help you today?"
    },
    "duration_ms": 2000
  }
}`}
</CollapsibleCodeBlock>

## Execution Optimizations

The engine implements several optimizations for efficient execution:

<Features>
  <Feature title="Parallel Processing" icon="/img/icons/hpc.svg">
    Independent nodes execute concurrently using async operations
  </Feature>
  <Feature title="Lazy Evaluation" icon="/img/icons/settings.svg">
    Nodes execute only when their outputs are needed
  </Feature>
  <Feature title="Resource Pooling" icon="/img/icons/database.svg">
    Connections to external services are pooled and reused
  </Feature>
</Features>

### Memory Management

<Tabs>
  <TabItem value="streaming" label="Streaming Data" default>
    <p>Large data outputs (e.g., from LLMs) are streamed rather than buffered entirely in memory.</p>
  </TabItem>
  
  <TabItem value="cleanup" label="Automatic Cleanup">
    <p>Node outputs are released from memory once all dependent nodes have consumed them.</p>
  </TabItem>
  
  <TabItem value="limits" label="Resource Limits">
    <p>Configurable limits on memory usage per node and total flow execution time.</p>
  </TabItem>
</Tabs>

## Execution Context

Each flow execution carries context that's available to all nodes:

<CollapsibleCodeBlock
  title="Execution Context Structure"
  description="Metadata available during flow execution"
  language="yaml"
>
{`metadata:
  execution_context:
    # L3 User Information
    user_id: "user_123"
    user_name: "John Doe"
    user_email: "john@example.com"
    wallet_address: "0x742d35Cc6634C0532925a3b844Bc9e7595f6E123"
    
    # Session Information
    session_id: "session_xyz789"
    session_count: 5
    
    # Execution Information
    flow_id: "flow_abc123"
    execution_id: "exec_def456"
    start_time: "2025-01-27T10:00:00Z"
    
    # Environment
    environment: "production"
    region: "us-east-1"
    
    # Custom Context (L2 defined)
    custom_data:
      feature_flags:
        premium_features: true
        beta_access: false`}
</CollapsibleCodeBlock>

<Callout type="info">
The execution context is injected into metadata nodes automatically and can be accessed by any node that needs user or session information.
</Callout>

## Comprehensive Execution Example

<Card>
  <CardHeader>
    <CardTitle>Complex Flow with Cross-Path Dependencies</CardTitle>
  </CardHeader>
  <div style={{ padding: '1rem' }}>
    <p>This example demonstrates backtracking, downward execution, and typed connections working together:</p>
    
    <CollapsibleCodeBlock
      title="Multi-Path Flow with Dependencies"
      description="A real-world scenario showing all execution concepts"
      language="yaml"
    >
{`# Flow: Customer service with premium/standard paths
nodes:
  start: { type: start }
  customer_data: { type: metadata }
  auth_service: { type: rest_api }  # Generates auth token
  router: { type: case }  # Routes based on customer tier
  
  # Premium path
  premium_ai: { type: llm_text, model: "gpt-4" }
  premium_formatter: { type: custom }
  
  # Standard path  
  standard_queue: { type: custom }
  standard_ai: { type: llm_text, model: "gpt-3.5" }
  # Note: standard_ai needs auth token from auth_service!
  
  response_merger: { type: merger }
  audit_logger: { type: custom }  # Logs all responses
  end: { type: end }

connections:
  # Initial setup
  - from_id: start
    to_id: customer_data
    connection_type: control
    
  - from_id: start
    to_id: auth_service
    connection_type: control
    
  - from_id: customer_data
    to_id: router
    from_output: "customer_data:tier"
    to_input: "router:variables.customer_tier"
    connection_type: both
    
  # Premium path (Case 1: tier == "premium")
  - from_id: router
    to_id: premium_ai
    connection_type: control  # Enabled by case
    
  - from_id: auth_service
    to_id: premium_ai
    from_output: "auth_service:token"
    to_input: "premium_ai:auth"
    connection_type: data  # Just data dependency
    
  - from_id: premium_ai
    to_id: premium_formatter
    connection_type: both
    
  # Standard path (Case 2: tier == "standard")  
  - from_id: router
    to_id: standard_queue
    connection_type: control  # Enabled by case
    
  - from_id: standard_queue
    to_id: standard_ai
    connection_type: control
    
  - from_id: auth_service
    to_id: standard_ai
    from_output: "auth_service:token"
    to_input: "standard_ai:auth"
    connection_type: data  # Cross-path dependency!
    
  # Convergence
  - from_id: premium_formatter
    to_id: response_merger
    connection_type: both
    
  - from_id: standard_ai
    to_id: response_merger
    connection_type: both
    
  - from_id: response_merger
    to_id: audit_logger
    connection_type: both
    
  - from_id: response_merger
    to_id: end
    connection_type: control
    
  - from_id: audit_logger
    to_id: end
    from_output: "audit_logger:log_id"
    to_input: "end:metadata.audit_id"
    connection_type: data

# Execution walkthrough for STANDARD customer:

1. start → customer_data, auth_service (parallel)
2. customer_data completes → router evaluates (tier="standard")
3. router disables premium path, enables standard path
4. router → standard_queue (control flow)
5. standard_queue → standard_ai (control flow)
6. standard_ai needs auth token (data dependency)
7. BACKTRACKING: auth_service executes if not already done
8. auth_service provides token to standard_ai (data flow)
9. standard_ai executes with auth token
10. standard_ai → response_merger
11. response_merger → audit_logger, end (parallel)
12. audit_logger provides log_id to end (data only)
13. Flow completes

Key points:
- premium_ai never executes (no control path)
- auth_service executes via backtracking if needed
- audit_logger and end run in parallel
- Data flows independently of control flow`}
    </CollapsibleCodeBlock>
  </div>
</Card>

## Best Practices

<Features>
  <Feature title="Design for Failure" icon="/img/icons/warning.svg">
    Include error handling paths and validation nodes
  </Feature>
  <Feature title="Minimize Dependencies" icon="/img/icons/network.svg">
    Reduce node dependencies for better parallelization
  </Feature>
  <Feature title="Use Streaming" icon="/img/icons/ai-workflow.svg">
    Enable streaming for LLM nodes to improve response times
  </Feature>
</Features>

### Execution Design Guidelines

<Callout type="success" title="Best Practices for Flow Execution">
1. **Use Typed Connections**: Be explicit about control vs data dependencies
2. **Plan for Backtracking**: Design with cross-path dependencies in mind
3. **Leverage Parallelism**: Use control connections to enable parallel execution
4. **Avoid Circular Dependencies**: Ensure your flow is a true DAG
5. **Test All Paths**: Verify both normal and backtracking scenarios
</Callout>

### Performance Tips

1. **Parallel Design**: Structure flows to maximize parallel execution
2. **Early Validation**: Validate inputs early to fail fast
3. **Selective Execution**: Use case nodes to avoid unnecessary processing
4. **Resource Management**: Set appropriate timeouts and memory limits

<CollapsibleCodeBlock
  title="Optimized Flow Design"
  description="Example of a well-designed flow for performance"
  language="yaml"
>
{`# Good: Parallel validation and processing
nodes:
  input_validator:
    type: custom
    # Validates input format
    
  permission_checker:
    type: custom
    # Checks user permissions
    
  # Both can run in parallel after input
connections:
  - from_id: chat_input
    to_id: input_validator
  - from_id: chat_input
    to_id: permission_checker
    
  # Process only if both succeed
  - from_id: input_validator
    to_id: processor
  - from_id: permission_checker
    to_id: processor`}
</CollapsibleCodeBlock>

## Monitoring and Debugging

### Execution Logs

Each node execution generates detailed logs:

```
[2025-01-27 10:00:00] INFO: Flow flow_abc123 started
[2025-01-27 10:00:01] DEBUG: Node chat_input_001 started with inputs: {...}
[2025-01-27 10:00:01] DEBUG: Node chat_input_001 completed in 50ms
[2025-01-27 10:00:02] INFO: Node llm_001 started
[2025-01-27 10:00:04] INFO: Node llm_001 completed in 2000ms
[2025-01-27 10:00:05] INFO: Flow flow_abc123 completed successfully
```

### Execution Metrics

Track key metrics for performance optimization:

- **Node Duration**: Time taken by each node
- **Queue Time**: Time spent waiting for dependencies
- **Total Duration**: End-to-end flow execution time
- **Resource Usage**: Memory and CPU per node

## Next Steps

<div style={{ display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(250px, 1fr))', gap: '1rem', marginTop: '1.5rem' }}>
  <Card>
    <CardHeader>
      <CardTitle>Elements Overview</CardTitle>
      <CardDescription>
        Explore the different types of nodes available
      </CardDescription>
    </CardHeader>
    <div style={{ padding: '1rem', paddingTop: 0 }}>
      <a href="./elements-overview" style={{ textDecoration: 'none' }}>
        Learn about elements →
      </a>
    </div>
  </Card>
  
  <Card>
    <CardHeader>
      <CardTitle>Connections</CardTitle>
      <CardDescription>
        Master data flow between nodes
      </CardDescription>
    </CardHeader>
    <div style={{ padding: '1rem', paddingTop: 0 }}>
      <a href="./connections" style={{ textDecoration: 'none' }}>
        Understand connections →
      </a>
    </div>
  </Card>
</div>